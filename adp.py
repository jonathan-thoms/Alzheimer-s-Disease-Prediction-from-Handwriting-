# -*- coding: utf-8 -*-
"""ADP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11cqhX1FBmcPvJeJNqeY0Ev_Jh2Jh7dc_
"""

!pip install torch torchvision torchaudio
!pip install tensorflow keras
!pip install opencv-python matplotlib numpy pandas
!pip install shap lime

from google.colab import drive
drive.mount('/content/drive')

import torch
print(torch.cuda.is_available())  # Should return True if GPU is enabled

import os
data_path = "/content/drive/MyDrive/Colab Notebooks/DARWIN"  # Change to your correct path
os.listdir(data_path)

import pandas as pd

# Load the dataset (replace 'darwin_data.csv' with the actual file name)
df = pd.read_csv(f"{data_path}/data.csv")

# Display basic info
print(df.info())

# Show first few rows
df.head()

# Check for missing values
print("Missing values:\n", df.isnull().sum())

# Identify numeric columns
numeric_cols = df.select_dtypes(include=['number']).columns

# Fill missing values only for numeric columns
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())


# Normalize features for better model performance

from sklearn.preprocessing import MinMaxScaler

# Identify numeric columns only
numeric_cols = df.select_dtypes(include=['number']).columns

# Initialize the scaler
scaler = MinMaxScaler()

# Scale only numeric columns
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

df.head()

from sklearn.model_selection import train_test_split

# Define features (X) and target (y)
X = df[numeric_cols]  # Only numeric features
y = df['class']       # Target variable (0 = healthy, 1 = Alzheimer's)

# Split into 80% training and 20% testing data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Check shapes
print(f"Training Data: {X_train.shape}, Testing Data: {X_test.shape}")

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# Force TensorFlow to use CPU
tf.config.set_visible_devices([], 'GPU')

# Check if GPU is available (should return 0)
print("Num GPUs Available:", len(tf.config.list_physical_devices('GPU')))

# Define the model architecture
model = Sequential([
    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dense(1, activation='sigmoid')  # Binary classification (0 = healthy, 1 = Alzheimer's)
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Print model summary
model.summary()

from sklearn.preprocessing import LabelEncoder

# Create label encoder instance
label_encoder = LabelEncoder()

# Fit and transform the target variable
y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.transform(y_test)  # Use the same encoder for test data

# Check conversion
print(y_train[:5])  # Should print numbers instead of letters

history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=16,
    validation_data=(X_test, y_test)
)

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)
print(f"Test Accuracy: {test_acc:.4f}")
print(f"Test Loss: {test_loss:.4f}")